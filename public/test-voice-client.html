<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SafeEscape Voice Assistant Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        .controls {
            margin: 20px 0;
        }
        button {
            padding: 10px 15px;
            margin-right: 10px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        #visualizer {
            width: 100%;
            height: 100px;
            background-color: #f0f0f0;
            margin: 20px 0;
        }
        .results {
            margin-top: 20px;
            padding: 10px;
            background-color: #f9f9f9;
            border-radius: 4px;
        }
        .error {
            color: red;
            margin: 10px 0;
        }
        #debugInfo {
            margin-top: 20px;
            padding: 10px;
            background-color: #f0f0f0;
            border-radius: 4px;
            white-space: pre-wrap;
        }
    </style>
</head>
<body>    <h1>SafeEscape Voice Assistant Test</h1>
    <p>Use this interface to test voice interactions with the SafeEscape emergency assistant.</p>
    <p><strong>Note:</strong> The system now supports recordings up to approximately 3 minutes. Longer recordings may be automatically split for processing.</p>
    
    <div class="controls">
        <button id="startBtn">Start Speaking</button>
        <button id="stopBtn" disabled>Stop</button>
        <span id="recordingTime" style="margin-left: 15px; font-weight: bold;"></span>
    </div>
    
    <canvas id="visualizer"></canvas>
    
    <div class="results">
        <h3>Results:</h3>
        <div id="transcription"></div>
        <div id="response"></div>
        <div id="error" class="error"></div>
    </div>
    
    <div id="debugInfo">
        <h3>Debug Information:</h3>
        <pre id="debugData"></pre>
    </div>
    
    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const visualizer = document.getElementById('visualizer');
        const transcriptionDiv = document.getElementById('transcription');
        const responseDiv = document.getElementById('response');
        const errorDiv = document.getElementById('error');
        const debugData = document.getElementById('debugData');
          let mediaRecorder;
        let audioChunks = [];
        let audioContext;
        let analyser;
        let canvas = visualizer.getContext('2d');
        let canvasWidth, canvasHeight;
        let animationId;
        let recordingStartTime;
        let recordingTimer;
        const recordingTimeDisplay = document.getElementById('recordingTime');
        
        function logDebug(message, data) {
            const timestamp = new Date().toISOString();
            let logMessage = `[${timestamp}] ${message}\n`;
            if (data) {
                try {
                    logMessage += typeof data === 'object' ? JSON.stringify(data, null, 2) : data;
                    logMessage += '\n';
                } catch (e) {
                    logMessage += `[Error serializing data: ${e.message}]\n`;
                }
            }
            debugData.textContent += logMessage;
            console.log(message, data);
        }
        
        function showError(message) {
            errorDiv.textContent = message;
            logDebug(`ERROR: ${message}`);
        }
        
        function clearError() {
            errorDiv.textContent = '';
        }
        
        function setupVisualizer(stream) {
            if (audioContext) audioContext.close();
            
            canvasWidth = visualizer.width = visualizer.offsetWidth;
            canvasHeight = visualizer.height = visualizer.offsetHeight;
            
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);
            
            draw();
        }
        
        function draw() {
            if (!analyser) return;
            
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            canvas.clearRect(0, 0, canvasWidth, canvasHeight);
            
            const draw = () => {
                animationId = requestAnimationFrame(draw);
                
                analyser.getByteFrequencyData(dataArray);
                
                canvas.fillStyle = '#f0f0f0';
                canvas.fillRect(0, 0, canvasWidth, canvasHeight);
                
                const barWidth = (canvasWidth / bufferLength) * 2.5;
                let barHeight;
                let x = 0;
                
                for (let i = 0; i < bufferLength; i++) {
                    barHeight = dataArray[i] / 2;
                    
                    canvas.fillStyle = `rgb(${barHeight + 100}, 50, 50)`;
                    canvas.fillRect(x, canvasHeight - barHeight, barWidth, barHeight);
                    
                    x += barWidth + 1;
                }
            };
            
            draw();
        }
        
        startBtn.addEventListener('click', async () => {
            clearError();
            transcriptionDiv.textContent = '';
            responseDiv.textContent = '';
            audioChunks = [];
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                logDebug('Microphone access granted');
                
                setupVisualizer(stream);
                
                // Try to use webm mimeType for better compatibility with Google Speech API
                const mimeType = 'audio/webm;codecs=opus';
                const options = { mimeType };
                
                try {
                    mediaRecorder = new MediaRecorder(stream, options);
                    logDebug('Using MIME type: ' + mimeType);
                } catch (e) {
                    logDebug('MIME type not supported, falling back to default', { error: e.message });
                    mediaRecorder = new MediaRecorder(stream);
                }
                
                mediaRecorder.addEventListener('dataavailable', event => {
                    audioChunks.push(event.data);
                });
                
                mediaRecorder.addEventListener('stop', async () => {
                    logDebug('Recording stopped, processing audio...');
                    
                    // Record as WebM to ensure compatibility with Google Speech API
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    logDebug(`Audio blob created: ${audioBlob.size} bytes`);
                    
                    try {
                        const base64Audio = await blobToBase64(audioBlob);
                        logDebug('Audio converted to Base64');                        // Detect the MIME type from the data URI to set proper encoding
                        const mimeType = base64Audio.split(';')[0].split(':')[1];
                        const isWebm = mimeType.includes('webm');
                        
                        const requestData = {
                            audio: base64Audio.split(',')[1],
                            audioConfig: {
                                encoding: isWebm ? 'WEBM_OPUS' : 'LINEAR16',
                                sampleRateHertz: 48000,
                                languageCode: 'en-US'
                            }
                        };
                        
                        logDebug('Audio format detection', {
                            detectedMimeType: mimeType,
                            usingEncoding: requestData.audioConfig.encoding
                        });
                        
                        logDebug('Sending audio to API', {
                            endpoint: '/api/voice/conversation',
                            audioLength: requestData.audio.length
                        });
                        
                        const response = await fetch('/api/voice/conversation', {
                            method: 'POST',
                            headers: {
                                'Content-Type': 'application/json'
                            },
                            body: JSON.stringify(requestData)
                        });
                        
                        logDebug(`API response status: ${response.status}`);
                        
                        if (!response.ok) {
                            const errorText = await response.text();
                            throw new Error(`API Error (${response.status}): ${errorText}`);
                        }
                        
                        const contentType = response.headers.get('Content-Type');
                        logDebug(`Response content type: ${contentType}`);
                        
                        if (contentType && contentType.includes('application/json')) {
                            const jsonResponse = await response.json();
                            logDebug('Received JSON response', jsonResponse);
                            
                            if (jsonResponse.transcription) {
                                transcriptionDiv.innerHTML = `<strong>You said:</strong> ${jsonResponse.transcription}`;
                            }
                            
                            if (jsonResponse.response) {
                                responseDiv.innerHTML = `<strong>Assistant:</strong> ${jsonResponse.response}`;
                            }
                            
                            if (jsonResponse.audioContent) {
                                try {
                                    const audioData = Uint8Array.from(atob(jsonResponse.audioContent), c => c.charCodeAt(0));
                                    const audioBlob = new Blob([audioData], { type: 'audio/mp3' });
                                    const audioUrl = URL.createObjectURL(audioBlob);
                                    
                                    const audio = new Audio(audioUrl);
                                    audio.onloadedmetadata = () => {
                                        logDebug(`Audio duration: ${audio.duration} seconds`);
                                    };
                                    audio.oncanplaythrough = () => {
                                        logDebug('Audio ready to play');
                                        audio.play();
                                    };
                                    audio.onerror = (e) => {
                                        showError(`Error playing audio: ${e.target.error.message || 'Unknown error'}`);
                                        logDebug('Audio error event', e);
                                    };
                                } catch (e) {
                                    showError(`Error processing audio data: ${e.message}`);
                                }
                            }
                        } else if (contentType && contentType.includes('audio/')) {
                            logDebug('Received audio response');
                            const audioBlob = await response.blob();
                            const audioUrl = URL.createObjectURL(audioBlob);
                            
                            try {
                                const audio = new Audio(audioUrl);
                                audio.onloadedmetadata = () => {
                                    logDebug(`Audio duration: ${audio.duration} seconds`);
                                };
                                audio.oncanplaythrough = () => {
                                    logDebug('Audio ready to play');
                                    audio.play();
                                };
                                audio.onerror = (e) => {
                                    showError(`Error playing audio: ${e.target.error.message || 'Unknown error'}`);
                                    logDebug('Audio error event', e);
                                };
                            } catch (e) {
                                showError(`Error playing audio: ${e.message}`);
                            }
                        } else {
                            const textResponse = await response.text();
                            logDebug('Received text response', textResponse);
                            responseDiv.innerHTML = `<strong>Response:</strong> ${textResponse}`;
                        }
                    } catch (e) {
                        showError(`Error processing response: ${e.message}`);
                    }
                    
                    // Clean up
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                    if (audioContext) {
                        audioContext.close().catch(e => logDebug(`Error closing audio context: ${e.message}`));
                    }
                });
                  mediaRecorder.start();
                logDebug('Recording started');
                
                // Start recording timer
                recordingStartTime = Date.now();
                updateRecordingTime();
                recordingTimer = setInterval(updateRecordingTime, 1000);
                
                startBtn.disabled = true;
                stopBtn.disabled = false;
            } catch (e) {
                showError(`Error accessing microphone: ${e.message}`);
            }
        });
          function updateRecordingTime() {
            if (!recordingStartTime) return;
            
            const elapsedMs = Date.now() - recordingStartTime;
            const seconds = Math.floor((elapsedMs / 1000) % 60);
            const minutes = Math.floor((elapsedMs / (1000 * 60)) % 60);
            
            recordingTimeDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
            
            // Add warning after 2.5 minutes
            if (elapsedMs > 150000) { // 2.5 minutes
                recordingTimeDisplay.style.color = 'red';
            }
        }
        
        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                logDebug('Recording stopped by user');
                
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                // Clear recording timer
                clearInterval(recordingTimer);
                recordingTimeDisplay.textContent = '';
                recordingTimeDisplay.style.color = '';
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        });
        
        function blobToBase64(blob) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsDataURL(blob);
            });
        }
        
        // Add a simple text-to-speech test
        const testTtsBtn = document.createElement('button');
        testTtsBtn.textContent = 'Test TTS Only';
        testTtsBtn.onclick = async () => {
            clearError();
            
            const testText = "This is a test of the emergency response system. If this were an actual emergency, you would be instructed where to go and what to do.";
            
            try {
                logDebug('Testing Text-to-Speech API', { text: testText });
                
                const response = await fetch('/api/voice/tts', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: testText })
                });
                
                logDebug(`TTS API response status: ${response.status}`);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`API Error (${response.status}): ${errorText}`);
                }
                
                const contentType = response.headers.get('Content-Type');
                logDebug(`TTS response content type: ${contentType}`);
                
                const audioBlob = await response.blob();
                logDebug(`Received audio blob: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
                
                const audioUrl = URL.createObjectURL(audioBlob);
                
                try {
                    const audio = new Audio(audioUrl);
                    audio.onloadedmetadata = () => {
                        logDebug(`Audio duration: ${audio.duration} seconds`);
                    };
                    audio.oncanplaythrough = () => {
                        logDebug('Audio ready to play');
                        audio.play();
                    };
                    audio.onerror = (e) => {
                        showError(`Error playing TTS audio: ${e.target.error.message || 'Unknown error'}`);
                        logDebug('Audio error event', e);
                    };
                } catch (e) {
                    showError(`Error playing TTS audio: ${e.message}`);
                }
                
                responseDiv.innerHTML = `<strong>TTS Test:</strong> ${testText}`;
            } catch (e) {
                showError(`TTS test error: ${e.message}`);
            }
        };
        
        document.querySelector('.controls').appendChild(testTtsBtn);
        
        // Log initial debug information
        logDebug('Page loaded. Browser info:', {
            userAgent: navigator.userAgent,
            audioContext: window.AudioContext ? 'Supported' : 'Not supported',
            mediaRecorder: window.MediaRecorder ? 'Supported' : 'Not supported'
        });
    </script>
</body>
</html>
